{
  "do_train" : true,
  "do_eval" : true,

  "task_type": "seq2seq",
  "training_type": "mle",

  "dataset_name": "multi_news_bl_art_own",
  "model_name_or_path": "facebook/bart-base",

  "output_dir": "../outputs/multi_news_bl_art_own/finetuned_abs/bart-base-O_dev",
  "logging_dir":"../outputs/multi_news_bl_art_own/finetuned_abs/bart-base-O_dev/log",

  "per_device_train_batch_size": 8,
  "per_device_eval_batch_size": 8,
  "gradient_accumulation_steps": 2,

  "num_train_epochs": 15,
  "lr_scheduler_type": "constant",
  "learning_rate": 3e-5,
  "max_grad_norm": 0.1,
  "label_smoothing_factor": 0.1, 

  "text_column": "summary_ext",
  "data_preprocess": "doc_trun",

  "report_to tensorboard": true,
  "overwrite_output_dir": true,
  "predict_with_generate": true,
  "save_model_accord_to_rouge": true,
  "evaluation_strategy": "steps",
  "save_strategy": "steps",

  "eval_steps": 500,
  "save_steps": 500,
  "save_total_limit": 1,
  "logging_steps": 20,
  "max_val_samples": 1000

}

